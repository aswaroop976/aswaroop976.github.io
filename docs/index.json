
[{"content":" Hi I am Arpan Swaroop # Welcome to my portfolio # GitHub - LinkedIn - Email # About Me: # I\u0026rsquo;m a computer engineer with a passion for embedded systems, computer security, computer networks, and computer architecture. Here you\u0026rsquo;ll find a showcase of my projects, skills, and experience.\nEducation # University of Illinois at Urbana Champaign # Degree: Bachelor of Science in Computer Engineering Graduation: May 2025 Courses Taken: Computer Organization and design, Computer security 1, Communication networks, Distributed systems, Parallel programming, Computer Systems Engineering, Database systems, Multimedia Signal Processing, Digital Signal Processing, Data structures and Algorithms Experience # Embedded developer for eCTF design/attack competition # Dates: Jan 2024 - May 2024 Key Contributions: Designed a secure embedded system for a medical infrastructure supply chain, used in medical devices(eg. infusion pumps) Led the build subteam to design a secure hardware abstraction layer for the MAX78000FTHR microcontroller, utilizing Rust Created a secure interface to interact with the True Random Number Generator (TRNG) and the I2C protocol Designed an intermediate layer between the I2C protocol and application layer, using the lightweight Ascon cipher and a three-way handshake to ensure confidentiality, integrity, authenticity, and replay-attack prevention. Built an automated attack platform to test and exploit vulnerabilities in competitors‚Äô designs Designed a secure user authorization protocol for protecting attestation data against microarchitectural side-channel attacks University of Illinois achieved 2nd place out of 76 teams in intercollegiate design/attack competition Research Assistant, Advanced Controls laboratory # Dates: Feb 2023 - Aug 2023 Responsibilities: Implemented path planning algorithms in quad-copters, to allow for autonomous flight Developed these algorithms using Euclidean signed distance fields for fast and flexible local planning Implemented the rapidly exploring random trees algorithm for efficient path planning Utilized Robot Operating System(ROS) to integrate the depth sense cameras used for localization and planning Developed on the Nvidia Xavier nx platform Web Developer Intern # Dates: Jun 2024 - Aug 2024 Key Contributions Redesigned landing page to include more modern and minimal UI/UX using Figma Implemented these changes using HTML/CSS and Javascript on the frontend Created a custom form, and connected it to a REST API written in Java using the Spring Boot framework Architected the integration of a relational database, designing the schema, and writing custom queries to handle user data for 100s of users Wrote a comprehensive business report about the impact of generative AI on low-code app building services Projects # (click on each link to go to a detailed post about every project)\nChip-8 microcontroller port # Rust, STM32F411\nBuilt CHIP-8 emulator and ported it to an embedded ARM microcontroller(STM32F411) Incorporated a display and buttons, utilizing an interrupt driven design Building an Out-of-Order Processor # System-verilog, Synopsis VCS, RISC-V asm\nDesigned and implemented a 32-bit out-of-order processor with explicit register renaming. Included a branch target buffer (BTB) and a G-share dynamic branch predictor. Utilized a split load stre queue, and stride prefetching Used SystemVerilog and Synopsys VCS for simulation and debugging. Achieved 3rd highest frequency in classwide design competition achieving an Fmax of 630 Mhz Unix-like 32-bit x86 Operating System # C, X86 asm\nArchitected a minimalistic multitasking operating system for x86 hardware, prioritizing efficiency and reliability Devised an interrupt-driven, time-slice-based CPU scheduling algorithm to schedule process execution Implemented support for round-robin process scheduling policy, with terminal switching Supported virtual memory using paging data-structures Developed a custom filesystem that supports basic file operations, utilizing storage, and I/O principles Thank you for visiting my portfolio! Feel free to reach out if you have any questions or collaboration ideas.\n","date":"26 January 2025","externalUrl":null,"permalink":"/","section":"","summary":"","title":"","type":"page"},{"content":" Out of Order processor design report # By Arpan Swaroop, Om Padmani, and Yugal Kithany # Introduction # This project centers on designing and implementing an Out-of-Order (OoO) microprocessor tailored for the RISC-V 32IM ISA. OoO microarchitectures have become essential for modern processor design, addressing growing commercial demands for computational efficiency and versatility. Our implementation employs Explicit Register Renaming (ERR), a strategic refinement over Tomasulo‚Äôs algorithm, effectively resolving potential issues such as excessive inputs to the Common Data Bus (CDB) and conflicts arising from simultaneous register writes. This report explains our design choices to enhance the performance and adaptability of our RISC-V processor by maximizing the instruction-level parallelism (ILP) and boosting instructions per cycle (IPC). Our design choices enhanced the utility of our base RISC-V implementation. Project overview # The first goal of this project was to address the baseline processor requirements such as OoO execution, memory instruction support, control instruction support, and general signed and unsigned multiplication, division, and arithmetic instructions. Past these initial goals, we hoped to have multiple advanced features that would allow us to increase our performance. We had aimed to implement a split load store queue, a branch predictor, and a prefetcher for both instruction and data accesses. These would be some enjoyable and attainable features to target that could significantly improve our performance. We were interested in one of the above features, leading to those specific ones being our choices. Figure 1: ERR block diagram.\nDesign description # Overview # This project was divided into three key checkpoints to promote consistent processor development. Each checkpoint significantly advanced the processor‚Äôs functionality and compatibility with the RISC-V ISA. We incorporated the instruction cache early in the first checkpoint to reduce the design integration overhead. This decision improved our experience implementing the memory instructions, enabling us to focus on writing clear RTL for the other deliverables. The cache line adapter was also written modularly to ensure ease of integrating prefetchers. We assessed the requirements of each checkpoint and planned out the specific aspect of the processor that each would focus on. This preparation allowed for a fair workload distribution and made us think about integration early on. Finally, the most notable cause for our success was creating a well-defined block diagram and datapath for the processor and specifying the significance of each module and its place in the puzzle.\nMilestones # Checkpoint 1 # The objectives of this checkpoint were to create a high-level microarchitecture diagram of the processor, shown in Figure 1, implement a parameterizable queue for internal instruction buffering, develop a cache-line adapter to handle DRAM bursts and integrate the fetch stage with a DRAM model. Specifically, our queue was circular with head and tail pointers that had one extra bit to signify what lap each pointer was on. Our cache-line adapter had stages in which we handled different aspects of the burst memory, such as initiating the memory request, each stage of the burst, and when the request was finished. Our high-level block diagram described our overall design of the ERR architecture and how each of the components would interact with each other. To test the developed RTL components, we utilized DUT testing on both the individual modules and the entire system once integrated. For instance, we tested the FIFO edge cases of enqueuing when full or dequeuing when empty before integrating the queue with the fetch stage. We also ensured the expected behavior was maintained when the queue wrapped around. Then, once integrated, we included more than 16 instructions(our instruction queue size is 16) to test the functionality thoroughly. To test the cache line adapter\u0026rsquo;s compatibility with the DRAM burst memory, we opened the simulated waveform and verified that each burst was handled correctly within the Mealy machine. Once this was done, we tested it on an assembly file and ensured all the correct instructions were formatted into the instruction queue. The outcome of this checkpoint was establishing a functional fetch stage and integrating it with DRAM memory and an instruction cache.\nCheckpoint 2 # For checkpoint 2, we had to implement all RV32I immediately and register instructions, excluding any control or memory instructions. We also had to integrate the multiplier and divider Synopsys IPs to implement the RISC-V M extension. This was the checkpoint where we had to design and implement most components in an explicit register renaming architecture. Checkpoint 1 was where we made the fetch stage; here, we made the components to implement the decode, execute, and write-back stages. In the decode stage, the first component is renamed dispatch. This is where we dispatch the instruction to the appropriate reservation station and the ROB queue. Additionally, rename dispatch is also where we dequeue a free register(for the destination register) from the free list and then update the register alias table(RAT) accordingly. Sitting in between decode and execution lies our reservation station. This is where we hold instructions until all the operands are ready for execution. For every functional unit, we chose to have a separate set of reservation stations; this just made it more streamlined for us to handle issuing instructions to the functional unit for execution. For our execute stage, we have our functional units; for this checkpoint, we included ALU/CMP, multiplication, and division functional units. We integrated given Synopsys multiplication and division IPs for our mul/div functional units. We chose sequential IPs to minimize our critical path and optimize our frequency. After executing the functional units, we have to broadcast the result on the central data bus(CDB) to the reservation stations, physical register file, return order buffer(ROB), and RAT. An important design choice we made was to have a separate CDB for each functional unit; this ensured that we could immediately broadcast the result as soon as it was ready, effectively minimizing wakeup latency. This was a tradeoff for a higher area, as each CDB is expensive area-wise because of the large amount of read/write ports that need to be synthesized. Finally, we reach the last part of the pipeline, the write-back stage; in this stage, we have the ROB and the retirement register alias table(RRAT). Our ROB is a first-in-first-out queue, which ensures that we commit instructions in the correct order; this is integral since we execute instructions out of order. The RRAT stores the last non-speculative architectural state of the processor and is updated whenever the ROB commits an instruction. Every instruction processed in our processor is speculative until the ROB commits it. So, it is important to store the last non-speculative state(this will be important when we implement control instructions). Moreover, once the RRAT receives an update, we enqueue the old register that was mapped back into the free list.\nFor testing, we utilized given assembly test cases, wrote our own test cases, and had a random testbench, which tested all the instructions that our processor was required to process. Our random testbench excluded all control and memory instructions. Using random testing, we were able to find and fix many bugs in how we processed certain instructions. For example, we had to deal with the divide by zero exception in our division IP.\nCheckpoint 3 # For checkpoint 3 we had to implement all of the control and memory instructions. This meant adding the load store queue module, the control functional unit, and the load store functional unit. We also had to make additions to the modules previously implemented such as adding control and memory stations to the reservation station and implementing flushing logic for mispredicted control instructions. Specifically for the load store queue, we made a FIFO where we enqueued into it from rename dispatch if the specific instruction was either a load or a store. The same instruction would then go through the reservation stations and load store functional unit to compute the address to load from or store to. This address would then be sent to the load store queue to update the index of the queue with the specific instruction‚Äôs memory address. If the head of the queue was a store, the address was ready, and it was at the top of the ROB, then we could proceed and execute it. If the head of the queue was a load and the address was ready we could proceed and execute it. The load store functional unit calculated the address from which to load from or store to using basic arithmetic operations. The control functional unit similarly calculated the address to branch/jump to as well as whether the branch should take place. This data was stored into the ROB and once the instruction became the head of the ROB, the branch/jump was taken if valid and the processor would flush all speculative values since we were statically predicting it to not be taken. to test for this checkpoint we used both the given test cases like coremark_im as well as our own targeted C and assembly files as test cases for individual components. We also modified our random testbench to include the new control and memory instructions. With the random tb along with the provided test cases passing, we were confident in our processors correctness.\nAdvanced Design Features # Next-line prefetcher(Instrution cache) # Design: The Next-Line Prefetcher sits between the fetch module and instruction cache. If the instruction queue is not full, the fetch module will request the next PC address. The prefetcher will intercept this request, and calculate a prefetch address (current PC + 32‚Äôh20) if it deems that a prefetch is necessary. It will then send the original request to the instruction cache. When it gets a response, it will send a request for the prefetched address, and hold the mem_r_data until the prefetch responds. Once this happens, the NL will send the mem_r_data from the original response to the fetch module. Testing: This was tested as a DUT first to make sure that the expected behavior occurs, and the stride increments correctly. Then, I tested this on coremark_im, but the stride value always increased to very large values, making it not beneficial to integrate into the final submission Performance Analysis: The Area increase with this advanced feature is 670.8184. The AMAT increases significantly from 31.086 to 38.58 on coremark_im after integrating this with the baseline, causing the IPC to decrease quite considerably from 0.3558 to 0.2927. This is likely due to a poor accuracy of only 34%, but we tried using different base stride values than 20 but it did not seem to help. It would likely have performed better if it was directly integrated into the cacheline adapter, but even then the accuracy would have been off, so perhaps the method of updating the stride did not work. The performance counters were done in the same way as the NL prefetcher. It was not integrated into main because of the very poor performance, Metric Value Area Increase: 670.8184 coremark_im Stride AMAT 38.5817820 Stride IPC 0.292752 no Stride AMAT 31.0864897 no Stride IPC 0.355823 Stride PF Accuracy: 34.331% G-share branch predictor with BTB # Overall design: Our branch prediction scheme involved a G-share branch predictor along with a BTB. We implemented both the branch predictor and the BTB in the fetch stage where we pass in the pc, and get the speculative branch prediction and branch target in the next clock cycle. We only speculatively take a branch if we both get a branch taken prediction from G-share, and a BTB hit. This is to ensure that whenever we speculatively branch we have a branch target to branch to\nBTB design: Our BTB is implemented using SRAM, where we had a 16 entry, direct mapped BTB. Each entry is indexed using the bottom 4 bits of the pc, and each entry is tagged with the top 28 bits of the pc of a valid control instruction. Additionally, each entry also stores a 32 bit branch target address. Whenever we get a BTB hit, we can be sure that the pc we used to index the BTB corresponds to a control instruction. We update the BTB whenever we mispredicted the branch target, or whenever we were supposed to non-speculatively branch and didn‚Äôt speculatively branch. The BTB works well with code that has branches that we take repeatedly like for loops. Tradeoffs with this design primarily include more area(primarily SRAM), and added critical path, because we input every PC we get from fetch into the BTB.\nG-share design: Our G-share uses a pattern history table implemented using SRAM, where we had 256 entries, each entry storing a 2-bit saturated counter. to index into this table we XOR the bottom 8 bits of the pc with the global history register(GHR). The GHR stores the outcomes of the last 8 non-speculative branches(1 for branch taken, 0 for branch not taken). Using the GHR we can take into account the global branch history of the program to index into the pattern history table. We update the pattern history table whenever we commit a control instruction, since two bit saturated counters need to be updated based on the outcome of the branch. to do this we store the pattern history table index in the rob queue entries for control instructions, so that we can update the pattern history table efficiently. The G-share branch predictor can be very accurate if the recent history of branch predictions determines the current branch prediction(such as nested if statements). Tradeoffs with this design include more area(primarily SRAM for pattern history table), and added critical path because we input every PC we get from fetch into the branch predictor.\nTesting: to test the BTB, I wrote a C file with nested for loops to test lots of repeated branches. to test G-share I wrote a simple Design Under Test test case, and tested it against the same nested for loop C file. I also made an assembly file to test all sorts of branch instructions, and to check various branching conditions.\nPerformance Analysis: Below I have compiled some performance metrics for the provided test cases. I also provide an explanation for each metric:\nG-share accuracy: (number of correct g-share predictions)/(number of control instructions committed). This metric represents how accurate the branch predictor‚Äôs predictions were in isolation(disregarding BTB hits). I calculated this by storing the G-share prediction for each control instruction in the rob queue entries, and checked if the prediction was correct at time of committing. Speculative branch prediction accuracy: (number of correctly speculated branches)/(number of control instructions committed). This is the most important statistic, where I measure how many correct speculative branches we take. BTB hit rate: (number of BTB hits)/(number of control instructions committed). This is represents how often we get a BTB hit Metric Coremark Mergesort FFT AES SHA G-share accuracy 87.82% 77.38% 99.04% 95.72% Speculative branch prediction accuracy 77.55% 68.14% 64.76% 18.74% BTB hit rate 49.93% 44.49% 78.26% 27.09% Branch predictor metrics\nBelow I also show performance speed up from incorporating BTB + G-share(IPC speedup and program delay speedup) Benchmark IPC (Base Design) Delay (Microseconds, Base Design) IPC (BTB + G-Share) Delay (Microseconds, BTB + G-Share) IPC Speedup Delay Decrease Coremark 0.2528 1845.12 0.3601 1287.49 42.44% speedup 30.22% decrease Mergesort 0.3269 2284.56 0.3905 1900.96 19.46% speedup 16.79% decrease FFT 0.3173 2594.53 0.373 2192.96 17.55% speedup 15.48% decrease AES SHA 0.2618 3990.69 0.273 3803.17 4.28% speedup 4.70% decrease Performance Metrics for Base Design and BTB + G-Share Integrated\nPerformance improvement chart\nConclusion # In this project we were tasked with creating an Out-of-Order processor tailored for the RISC-V 32IM ISA. We were assigned this to gain a deep understanding of advanced computer architecture concepts, and as a design challenge to design the most performant and efficient microprocessor. As discussed earlier, Out-of-Order microarchitectures are ubiquitous with modern day processors, and throughout this project we sought to emulate and improve on designs taught to us in class. I believe we were successful in this endeavor choosing to go with an ERR architecture, and the integration of several advanced features such as a nextline/stride prefetcher, G-share branch predictor, branch target buffer, and a split load store queue. Throughout this we also learned a lot to improve upon in future designs, such as incorporating performance testing earlier on to find bottlenecks earlier on and making each component more modular to make integration more streamlined. Overall this project will serve as valuable experience setting us up for success in our future careers in computer architecture.\n","date":"26 January 2025","externalUrl":null,"permalink":"/projects/ooo_processor/","section":"Projects","summary":"","title":"OOO_processor","type":"projects"},{"content":"","date":"26 January 2025","externalUrl":null,"permalink":"/projects/","section":"Projects","summary":"","title":"Projects","type":"projects"},{"content":" CHIP-8 emulator in Rust ported to the STM32f411 microcontroller # This project was inspired by this blog post: https://dhole.github.io/post/chip8_emu_2/ Here I will explain how I wrote a CHIP-8 emulator and ported it to an embedded ARM microcontroller, if you are curious about all the code here is the repository linked(ignore the name of the repository): https://github.com/aswaroop976/ssd1306_test I will split this post into two parts first talking about the backend, which consists of the CHIP-8 emulator, and then the frontend, which is where I will explain how I ported this emulator to a micrcontroller and interfaced with a display and buttons Additionally this post assumes pre-requisite knowledge of Rust(nothing too complex), and a basic understanding of computer architecture and embedded systems(although I will try to make this as beginner friendly as possible, linking to helpful resources whereever I can) Backend(CHIP-8 emulator) # This part of the project was largely inspired from this blog post(seriously this post probably explains things way better than I ever can): https://austinmorlan.com/posts/chip8_emulator/ Chip8 struct # First I defined a Chip8 struct where I store the state of the emulator at any point in time:\npub struct Chip8 { pub memory: [u8; MEMORY_SIZE], // 4kb memory pub registers: [u8; REGISTER_COUNT], // 16 general purpose registers pub index_register: u16, pub program_counter: u16, pub screen: [u8; SCREEN_WIDTH * SCREEN_HEIGHT], // 64x32 pixel display pub delay_timer: u8, pub sound_timer: u8, pub return_stack: [u16; STACK_SIZE], // return_stack with 16 levels pub stack_pointer: u8, // return_stack pointer pub keys: [u8; REGISTER_COUNT], pub jump_table: [OpcodeHandler; 16], } Important fields\nreturn stack: This essentially serves as the return address stack. A stack depth of 16 limits the number or recursive function calls to 16. The stack pointer field points to the top of the return address stack. memory: the CHIP-8 contains a 4kb memory address space, which requires 16 bits to fully address. However the general purpose registers are only 8 bits wide, to account for this there is a special 16 bit index register. The index register is used specifically to store memory addresses screen: This represents a seperate memory buffer to drive the 64x32 CHIP-8 display. The display is monochrome(black and white), so the pixel values are either 1(on), or 0(off). keys: CHIP-8 has 16 input keys, the first 16 hexadecimal values: 0 through F, each key is pressed or not jump table: This is where we will process opcodes and use function pointers to jump to appropriate opcode handler fuction for every instruction that we read from ROM files Opcodes # For every opcode present in the Chip8 ISA(instruction set architecture), I created an opcode handler function, eg:\n// DRW Vx, Vy, nibble // Instruction: display n-byte sprite starting at memory location I at (Vx, Vy), set VF = // collision fn drw_vx_vy_nibble(\u0026amp;mut self, opcode: u16) { let x = ((opcode \u0026amp; 0x0F00) \u0026gt;\u0026gt; 8) as usize; let y = ((opcode \u0026amp; 0x00F0) \u0026gt;\u0026gt; 4) as usize; let height = (opcode \u0026amp; 0x000F) as usize; let vx = self.registers[x] as usize; let vy = self.registers[y] as usize; self.registers[0xF] = 0; for row in 0..height { let sprite_byte = self.memory[self.index_register as usize + row]; for col in 0..8 { let sprite_pixel = sprite_byte \u0026amp; (0x80 \u0026gt;\u0026gt; col); let screen_index = (vy + row) * SCREEN_WIDTH + (vx + col); if screen_index \u0026lt; self.screen.len() { let screen_pixel = \u0026amp;mut self.screen[screen_index]; if sprite_pixel != 0 { if *screen_pixel == 1 { self.registers[0xF] = 1; } *screen_pixel ^= 1; } } } } } In this instruction I have to modify the screen field by drawing a sprite at the specified location, this is the main way that CHIP-8 programs interact with the display Emulation cycle # Here I present my emulate cycle function where I perform the fetch/decode/execute stages of the CHIP-8 emulator(My opcode handlers deal with memory instructions, as well as writing to registers). The fetch opcode instruction is a helper function to fetch instructions\npub fn fetch_opcode(\u0026amp;self) -\u0026gt; u16 { let high_byte = self.memory[self.program_counter as usize] as u16; let low_byte = self.memory[(self.program_counter + 1) as usize] as u16; (high_byte \u0026lt;\u0026lt; 8) | low_byte } pub fn emulate_cycle(\u0026amp;mut self) { let opcode = self.fetch_opcode(); self.program_counter += 2; let index = (opcode \u0026amp; 0xF000) \u0026gt;\u0026gt; 12; let handler = self.jump_table[index as usize]; handler(self, opcode); if self.delay_timer \u0026gt; 0 { self.delay_timer -= 1; } if self.sound_timer \u0026gt; 0 { self.sound_timer -= 1; } } After loading the ROM into the Chip8‚Äôs memory(expanded on below), I fetch the current instruction using the program counter(this points to the instruction to be fetched). Then I increment the program counter to point to the next instruction to be fetched(for control/branch instructions the opcode handler will set the program counter accordingly). Then using the opcode from the instruction fetched I can get the relevant opcode handler from the jump table.\nBelow I show the load program function which is how I load a buffer containing the ROM instructions into the chip8‚Äôs memory(instructions from the ROM shoud be stored in the range 0x200 to 0xFFF in the chip8 memory):\npub fn load_program(\u0026amp;mut self, program: \u0026amp;[u8]) { for (i, \u0026amp;byte) in program.iter().enumerate() { self.memory[0x200 + i] = byte; } } Frontend(Microcontroller port) # Hardware # STM32F411\nI chose the STM32F411, successor to the popular ‚Äúblue-pill‚Äù STM32 micrcontroller, because of it‚Äôs robust Rust support and powerful internals(for a microcontroller) The specs include: 512 Kb of flash memory, 128 Kb of SRAM 32 bit ARM Cortex-M4 CPU that can be clocked up to 100Mhz Many peripherals SSD1306 display\nI chose this display because of its cheap price and robust Rust support Software # This was a learning experience with using Rust for an embedded system, as such I will document the libraries/crates I used, as well discoveries I made about writing bare-metal Rust Crates used\nstm32f4xx-hal: This is the main crate I used to interact with the stm32f411, as it is a multi-device hardware abstraction layer for all STM32F4 series microcontrollers. This crate provided an API to interface with the peripherals on the microcontroller, such as the GPIO pins, timers, clock, SPI, etc. cortex-m-rt: This crate contains all the required parts to build an application containing no standard library, that targets a Cortex-M microcontroller. I used it to define an entry point of the program(the main function) ssd1306: This crate provided a driver interface with the ssd1306 display, it supports both I2C and SPI. I used I2C for this project embedded-graphics: This crate is a 2D graphics library for memory constrained embedded devices. I used this crate(alongside the ssd1306 crate) as a helpful abstraction to draw individual points on the screen Code overview\nThis is how I setup the clock, GPIO pins, and the display initially in the main function:\nfn main() -\u0026gt; ! { rtt_init_print!(); let dp = pac::Peripherals::take().unwrap(); // Set up the system clock. let rcc = dp.RCC.constrain(); let clocks = rcc.cfgr.sysclk(100.MHz()).freeze(); // Set up I2C - SCL is PB6 and SDA is PB7; they are set to Alternate Function 4 let gpiob = dp.GPIOB.split(); let scl = gpiob.pb6.internal_pull_up(true); let sda = gpiob.pb7.internal_pull_up(true); // Configure PB0 as an output pin (connected to one side of the button) let mut output_pin: PB0\u0026lt;Output\u0026lt;PushPull\u0026gt;\u0026gt; = gpiob.pb0.into_push_pull_output(); // Configure PB1 as an input pin as pull down input let input_pin: PB1\u0026lt;Input\u0026gt; = gpiob.pb1.into_pull_down_input(); output_pin.set_high(); let i2c = dp.I2C1.i2c((scl, sda), 400.kHz(), \u0026amp;clocks); // Set up the display let interface = I2CDisplayInterface::new(i2c); let mut disp = Ssd1306::new(interface, DisplaySize128x64, DisplayRotation::Rotate0) .into_buffered_graphics_mode(); disp.init().unwrap(); disp.flush().unwrap(); let mut chip8 = Chip8::new(); // Load ROM ================================================================ const CHIP8_ROM: \u0026amp;[u8] = include_bytes!(\u0026quot;../Chip8 Picture.ch8\u0026quot;); // Load the program into the CHIP-8 emulator chip8.load_program(\u0026amp;CHIP8_ROM); I set the clock frequency to about 100Mhz here, and use pins pb6 and pb7 to drive the I2C output. pb6 serves as the serial clock line(SCL) and pb7 serves as serial data line(SDA).\nThe I2C speed mode I set the pins to is Fast mode considering I am driving the I2C display at 400kHZ(the max rate for this microcontroller). This means the transmission speed is approximately 400kbps\nUsing the ssd1306 crate I am able to setup my display, using the I2C interface I setup earlier I am currently using a singular button(even though CHIP-8 has 16 buttons, I didn‚Äôt have enough wires to connect all 16 buttonsüò≠)\nHere pressing the button closes a circuit between pin pb0 and pb1, where pin pb0 is outputting a voltage(3.3v). Therefore whenever pin pb0(set to be a pull-down input) detects a voltage, we detect a button press. Very useful if I had more wires however to connect all 16 buttons on my makeshift keypad. I took .ch8 binaries that I found online, and using include bytes was able to write the instructions into a buffer, which I then load into the chip8‚Äôs memory using the load program function(more info on this on the chip8 section)\nBelow I present the main loop that runs after the system is setup and initialized:\nloop { // Emulate cycle: chip8.emulate_cycle(); // Draw logic here ===================================================== disp.flush().unwrap(); for (i, \u0026amp;pixel) in chip8.screen.iter().enumerate() { if pixel == 1 { let x = 32 + ((i % SCREEN_WIDTH) as i32); let y = 17 + (i / SCREEN_WIDTH) as i32; Pixel(Point::new(x, y), BinaryColor::On) .draw(\u0026amp;mut disp) .unwrap(); } } } Here I emulate the chip8 clock cycle by calling the emulate cycle and draw to the display To draw to the screen I iterate through the screen buffer in the chip8 struct and using the embedded-graphics crate turn each pixel on the ssd1306 on/off based on the value in the screen buffer. ","date":"21 January 2025","externalUrl":null,"permalink":"/projects/chip8_microcontroller_port/","section":"Projects","summary":"","title":"Chip8_microcontroller_port","type":"projects"},{"content":"","date":"21 January 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]